{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5aD6kkpggmT"
   },
   "source": [
    "## Fashion Classification with Monk and Densenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_VzhZ8Eoy6W"
   },
   "source": [
    "## Blog Post -- [LINK]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q6CQ5Hztgk_u"
   },
   "source": [
    "#### Explanation of Dense blocks and Densenets\n",
    "\n",
    "[BLOG LINK](https://towardsdatascience.com/review-densenet-image-classification-b6631a8ef803)\n",
    "\n",
    "This is an excellent read comparing Densenets with other architectures and why Dense blocks achieve better accuracy while training lesser parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODQ8TgEfh9p2"
   },
   "source": [
    "#### Setup Monk\n",
    "\n",
    "We begin by setting up monk and installing dependencies for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uHXW_3v8eESq"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Tessellate-Imaging/monk_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rEBAqVdreES3"
   },
   "outputs": [],
   "source": [
    "cd monk_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zSGwzNCeETL"
   },
   "outputs": [],
   "source": [
    "!pip install -r installation/requirements_cu10.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JRS-V8JeETP"
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-AThUTWXiEYT"
   },
   "source": [
    "#### Prepare Dataset\n",
    "\n",
    "Next we grab the dataset. \n",
    "Credits to the original dataset -- [Kaggle](https://www.kaggle.com/paramaggarwal/fashion-product-images-small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4eAObnaeETW"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/wzgyr1dx4sejo5u/dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihja_mZMeb5T"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "smdGh1FRi5ZH"
   },
   "source": [
    "**Note** : Pytorch backend requires the images to have 3 channels when loading. We prepare a modified dataset for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "snq9tkDNTZ9w"
   },
   "outputs": [],
   "source": [
    "!mkdir mod_dataset\n",
    "!mkdir mod_dataset/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHX76Ln2S8mw"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert23channel(imagePath):\n",
    "  #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  img = cv2.imread(imagePath)\n",
    "  img2 = np.zeros_like(img)\n",
    "  b,g,r = cv2.split(img)\n",
    "  img2[:,:,0] = b\n",
    "  img2[:,:,1] = g\n",
    "  img2[:,:,2] = r\n",
    "  return img2\n",
    "\n",
    "imageList = glob(\"./dataset/images/*.jpg\")\n",
    "for i in tqdm(imageList):\n",
    "  inPath = i\n",
    "  out = convert23channel(inPath)\n",
    "  outPath = \"./mod_dataset/images/{}\".format(inPath.split('/')[-1])\n",
    "  cv2.imwrite(outPath,out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAxslxz1jb2h"
   },
   "source": [
    "#### Data exploration [DOCUMENTATION](https://clever-noyce-f9d43f.netlify.com/#/compare_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plD4piX6eETw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gt = pd.read_csv(\"./dataset/styles.csv\",error_bad_lines=False)\n",
    "gt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bzf6HOP_jf-i"
   },
   "source": [
    "The dataset labels have multiple classification categories. We will train the sub category labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B99s9woOjtEz"
   },
   "source": [
    "Extract the sub category labels for images. The image id fields require image names with extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crX8cc_CZsSi"
   },
   "outputs": [],
   "source": [
    "label_gt = gt[['id','subCategory']]\n",
    "label_gt['id'] = label_gt['id'].astype(str) + '.jpg'\n",
    "\n",
    "label_gt.to_csv('./mod_dataset/subCategory.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2nyNrvsCkAGm"
   },
   "source": [
    "# Pytorch with Monk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ayt8tRiRj8dK"
   },
   "source": [
    "## Create an Experiment [DOCS](https://clever-noyce-f9d43f.netlify.com/#/quick_mode/quickmode_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXJd1TN4kDbX"
   },
   "source": [
    "Import Monk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Yb0HvnieEUE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"./monk_v1/monk/\");\n",
    "import psutil\n",
    "from pytorch_prototype import prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUaMvV5EmELj"
   },
   "source": [
    "## Experiment 1 with Densenet121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_hUoIGRrkFUA"
   },
   "source": [
    "Create a new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0xYCSGqeEUF"
   },
   "outputs": [],
   "source": [
    "ptf = prototype(verbose=1);\n",
    "ptf.Prototype(\"fashion\", \"exp1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xch81jrBkI9L"
   },
   "source": [
    "Load the training images and ground truth labels for sub category classification.\n",
    "We select **densenet121** as our neural architecture and set number of epochs to **5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8f-zMN5eEUH"
   },
   "outputs": [],
   "source": [
    "ptf.Default(dataset_path=\"./mod_dataset/images\", path_to_csv=\"./mod_dataset/subCategory.csv\", model_name=\"densenet121\", freeze_base_network=True, num_epochs=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5f5zi5Ekc5V"
   },
   "source": [
    "**Note** : The dataset has a few missing images. We can find the missing and corrupt images by performing EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xax9l6esfhj"
   },
   "source": [
    "## EDA documentation [DOCS](https://clever-noyce-f9d43f.netlify.com/#/aux_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-MttXQlVYtth"
   },
   "outputs": [],
   "source": [
    "ptf.EDA(check_missing=True, check_corrupt=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qS0OIeAJkl-X"
   },
   "source": [
    "#### Clean the labels file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNObzCCPeETt"
   },
   "outputs": [],
   "source": [
    "corruptImageList = ['39403.jpg','39410.jpg','39401.jpg','39425.jpg','12347.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOQs-5QAXkDg"
   },
   "outputs": [],
   "source": [
    "def cleanCSV(csvPath,labelColumnName,imageIdColumnName,appendExtension=False,extension = '.jpg',corruptImageList = []):\n",
    "  gt = pd.read_csv(csvPath, error_bad_lines=False)\n",
    "  print(\"LABELS\\n{}\".format(gt[\"{}\".format(labelColumnName)].unique()))\n",
    "  label_gt = gt[[\"{}\".format(imageIdColumnName),\"{}\".format(labelColumnName)]]\n",
    "  if appendExtension == True:\n",
    "    label_gt['id'] = label_gt['id'].astype(str) + extension\n",
    "  for i in corruptImageList:\n",
    "    label_gt = label_gt[label_gt.id != i]\n",
    "  print(\"Total images : {}\".format(label_gt.shape[0]))\n",
    "  return label_gt\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6yzJK7iabH6"
   },
   "outputs": [],
   "source": [
    "subCategory_gt = cleanCSV('./dataset/styles.csv','subCategory','id',True,'.jpg',corruptImageList)\n",
    "subCategory_gt.to_csv(\"./mod_dataset/subCategory_cleaned.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6pKwJZclcGJ"
   },
   "source": [
    "## Update the experiment [DOCS](https://clever-noyce-f9d43f.netlify.com/#/update_mode/update_dataset)\n",
    "Now that we have a clean ground truth labels file and modified images, we can update the experiment to take these as our inputs.\n",
    "**Note** Remember to reload the experiment after any updates. Check out the docs -- [DOCUMENTATION](https://clever-noyce-f9d43f.netlify.com/#/update_mode/update_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3sycoSCObswh"
   },
   "outputs": [],
   "source": [
    "ptf.update_dataset(dataset_path=\"./mod_dataset/images\",path_to_csv=\"./mod_dataset/subCategory_cleaned.csv\");\n",
    "ptf.Reload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5zc0H4UslvOj"
   },
   "source": [
    "#### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxa8jJGEtyAw"
   },
   "outputs": [],
   "source": [
    "ptf.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k1U0fdQSlzS3"
   },
   "source": [
    "After training for 5 epochs we reach a validation accuracy of 89% which is quite good. Lets see if other densenet architectures can help improve this performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UUM_Pt6Yl_ly"
   },
   "source": [
    "## Experiment 2 with Densenet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "po_iE00jtzjB"
   },
   "outputs": [],
   "source": [
    "ptf = prototype(verbose=1);\n",
    "ptf.Prototype(\"fashion\", \"exp2\");\n",
    "ptf.Default(dataset_path=\"./mod_dataset/images\", path_to_csv=\"./mod_dataset/subCategory_cleaned.csv\", model_name=\"densenet169\", freeze_base_network=True, num_epochs=5);\n",
    "ptf.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dnIBR-LmK8J"
   },
   "source": [
    "We do improve the validation accuracy but not much. Next we run the experiment with densenet201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1t36f4fjmRX5"
   },
   "source": [
    "## Experiment 3 with Densenet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1yF70Bfc4Uif"
   },
   "outputs": [],
   "source": [
    "ptf = prototype(verbose=1);\n",
    "ptf.Prototype(\"fashion\", \"exp3\");\n",
    "ptf.Default(dataset_path=\"./mod_dataset/images\", path_to_csv=\"./mod_dataset/subCategory_cleaned.csv\", model_name=\"densenet201\", freeze_base_network=True, num_epochs=5);\n",
    "ptf.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GXld6BaImceJ"
   },
   "source": [
    "We can see that the 3 versions of densenet give us quite similar results. We can quickly compare the experiments to see variations in losses and training times to choose a fitting experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BAKe_8SDmoUw"
   },
   "source": [
    "## Compare experiments [DOCS](https://clever-noyce-f9d43f.netlify.com/#/compare_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7jOO3i-CYw9"
   },
   "outputs": [],
   "source": [
    "from compare_prototype import compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SO-0jraIcok"
   },
   "outputs": [],
   "source": [
    "ctf = compare(verbose=1);\n",
    "ctf.Comparison(\"Fashion_Pytorch_Densenet\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2_dADhxIikT"
   },
   "outputs": [],
   "source": [
    "ctf.Add_Experiment(\"fashion\", \"exp1\");\n",
    "ctf.Add_Experiment(\"fashion\", \"exp2\");\n",
    "ctf.Add_Experiment(\"fashion\", \"exp3\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbCn8JHQIrE-"
   },
   "outputs": [],
   "source": [
    "ctf.Generate_Statistics();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5oOZNjW6ms0t"
   },
   "source": [
    "# Gluon with Monk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ok-f3blkmv8g"
   },
   "source": [
    "Lets repeat the same experiments but while using a different backend framework **Gluon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgCKBKbPPagg"
   },
   "outputs": [],
   "source": [
    "from gluon_prototype import prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPVTqf9Xm7vI"
   },
   "source": [
    "#### Experiment 4 with Densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-0AkkxwoY6C1"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"fashion\", \"exp4\");\n",
    "gtf.Default(dataset_path=\"./mod_dataset/images\", path_to_csv=\"./mod_dataset/subCategory_cleaned.csv\", model_name=\"densenet121\", freeze_base_network=True, num_epochs=5);\n",
    "gtf.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJ0GTIIOnMOm"
   },
   "source": [
    "#### Experiment 5 with Densenet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rxPF5UBdZAil"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"fashion\", \"exp5\");\n",
    "gtf.Default(dataset_path=\"./mod_dataset/images\", path_to_csv=\"./mod_dataset/subCategory_cleaned.csv\", model_name=\"densenet169\", freeze_base_network=True, num_epochs=5);\n",
    "gtf.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q3ugRwzunPSh"
   },
   "source": [
    "#### Experiment 6 with Densenet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgmbtFwShsGK"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"fashion\", \"exp6\");\n",
    "gtf.Default(dataset_path=\"./mod_dataset/images\", path_to_csv=\"./mod_dataset/subCategory_cleaned.csv\", model_name=\"densenet201\", freeze_base_network=True, num_epochs=5);\n",
    "gtf.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_92RX6I3nko1"
   },
   "source": [
    "Lets compare the performance of Gluon backend and Densenet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDXIqe68w9wX"
   },
   "outputs": [],
   "source": [
    "ctf = compare(verbose=1);\n",
    "ctf.Comparison(\"Fashion_Gluon_Densenet\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGl6BB6kn92R"
   },
   "outputs": [],
   "source": [
    "ctf.Add_Experiment(\"fashion\", \"exp4\");\n",
    "ctf.Add_Experiment(\"fashion\", \"exp5\");\n",
    "ctf.Add_Experiment(\"fashion\", \"exp6\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBzcYFFLoBfo"
   },
   "outputs": [],
   "source": [
    "ctf.Generate_Statistics();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hxx8OKdDo830"
   },
   "source": [
    "We can also compare how Pytorch and Gluon fared with our training, but before that lets use Keras backend to train densenets and compare all three frameworks together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Ad6zOyypH3Y"
   },
   "source": [
    "# Keras with Monk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiJpyZ3XpGO2"
   },
   "outputs": [],
   "source": [
    "from keras_prototype import prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UQNufeOpkxX"
   },
   "source": [
    "#### Experiment 7 with Densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7aqbERNpkdj"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "ktf = prototype(verbose=1);\n",
    "ktf.Prototype(\"fashion\", \"exp7\");\n",
    "ktf.Default(dataset_path=\"./mod_dataset/images\", path_to_csv=\"./mod_dataset/subCategory_cleaned.csv\", model_name=\"densenet121\", freeze_base_network=True, num_epochs=5);\n",
    "ktf.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yn47WN79pz0O"
   },
   "source": [
    "#### Experiment 8 with Densenet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhGkjGUBp2MH"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "ktf = prototype(verbose=1);\n",
    "ktf.Prototype(\"fashion\", \"exp8\");\n",
    "ktf.Default(dataset_path=\"./mod_dataset/images\", path_to_csv=\"./mod_dataset/subCategory_cleaned.csv\", model_name=\"densenet169\", freeze_base_network=True, num_epochs=5);\n",
    "ktf.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "liImz__jp7AH"
   },
   "source": [
    "#### Experiment 9 with Densenet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZEyqZMCNp9cL"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "ktf = prototype(verbose=1);\n",
    "ktf.Prototype(\"fashion\", \"exp9\");\n",
    "ktf.Default(dataset_path=\"./mod_dataset/images\", path_to_csv=\"./mod_dataset/subCategory_cleaned.csv\", model_name=\"densenet201\", freeze_base_network=True, num_epochs=5);\n",
    "ktf.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DDpFfQjqCPH"
   },
   "source": [
    "# Compare experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lB3fzO5IqF2a"
   },
   "source": [
    "After using different architectures and backend frameworks, lets compare their performance on accuracy, losses and resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_HBgKNW5qEx6"
   },
   "outputs": [],
   "source": [
    "ctf = compare(verbose=1);\n",
    "ctf.Comparison(\"Fashion_Densenet_Compare\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mU3FJs_qV0p"
   },
   "outputs": [],
   "source": [
    "ctf.Add_Experiment(\"fashion\", \"exp1\");\n",
    "ctf.Add_Experiment(\"fashion\", \"exp2\");\n",
    "ctf.Add_Experiment(\"fashion\", \"exp3\");\n",
    "ctf.Add_Experiment(\"fashion\", \"exp4\");\n",
    "ctf.Add_Experiment(\"fashion\", \"exp5\");\n",
    "ctf.Add_Experiment(\"fashion\", \"exp6\");\n",
    "ctf.Add_Experiment(\"fashion\", \"exp7\");\n",
    "ctf.Add_Experiment(\"fashion\", \"exp8\");\n",
    "ctf.Add_Experiment(\"fashion\", \"exp9\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AxeS1_w1qbop"
   },
   "outputs": [],
   "source": [
    "ctf.Generate_Statistics();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gq8C3TFdqimr"
   },
   "source": [
    "You can find the generated plots inside **workspace/comparison/Fashion_Densenet_Compare**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VfxmdIfMqqtS"
   },
   "source": [
    "Lets visualise the training accuracy and GPU utilisation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNTyvTPtqpdE"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('workspace/comparison/Fashion_Densenet_Compare/train_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X7rHuN6ArKKl"
   },
   "outputs": [],
   "source": [
    "Image('workspace/comparison/Fashion_Densenet_Compare/stats_training_time.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fashion_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
